"""
ç²¾ç°¡ Tesseract è³‡æ–™å¤¾
ç§»é™¤ä¸éœ€è¦çš„èªè¨€åŒ…å’Œè¨“ç·´å·¥å…·ï¼Œåªä¿ç•™ OCR è¾¨è­˜æ‰€éœ€çš„æª”æ¡ˆ
"""
import os
import shutil

def print_section(title):
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)

def get_folder_size(folder_path):
    """è¨ˆç®—è³‡æ–™å¤¾å¤§å°ï¼ˆMBï¼‰"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(folder_path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            if os.path.exists(fp):
                total_size += os.path.getsize(fp)
    return total_size / (1024 * 1024)

def remove_files(base_path, files_to_remove, description):
    """ç§»é™¤æŒ‡å®šçš„æª”æ¡ˆ"""
    removed_count = 0
    saved_size = 0
    
    for file_name in files_to_remove:
        file_path = os.path.join(base_path, file_name)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path) / (1024 * 1024)
            try:
                os.remove(file_path)
                removed_count += 1
                saved_size += size
                print(f"  âœ“ ç§»é™¤: {file_name} ({size:.2f} MB)")
            except Exception as e:
                print(f"  âœ— ç„¡æ³•ç§»é™¤: {file_name} - {e}")
    
    return removed_count, saved_size

def main():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    tesseract_dir = os.path.join(script_dir, "tesseract")
    
    print_section("Tesseract è³‡æ–™å¤¾ç²¾ç°¡å·¥å…·")
    
    if not os.path.exists(tesseract_dir):
        print(f"âŒ æ‰¾ä¸åˆ° tesseract è³‡æ–™å¤¾: {tesseract_dir}")
        input("æŒ‰ Enter é€€å‡º...")
        return
    
    # è¨ˆç®—åŸå§‹å¤§å°
    original_size = get_folder_size(tesseract_dir)
    print(f"\nğŸ“Š åŸå§‹å¤§å°: {original_size:.2f} MB")
    
    # 1. ç§»é™¤ä¸éœ€è¦çš„èªè¨€åŒ…ï¼ˆåªä¿ç•™è‹±æ–‡ï¼‰
    print("\n[æ­¥é©Ÿ 1/4] ç§»é™¤å¤šé¤˜çš„èªè¨€åŒ…...")
    tessdata_dir = os.path.join(tesseract_dir, "tessdata")
    
    # ä¿ç•™ eng.traineddataï¼Œç§»é™¤å…¶ä»–èªè¨€åŒ…
    unnecessary_languages = [
        "chi_tra.traineddata",      # ç¹é«”ä¸­æ–‡ (2.26 MB)
        "chi_tra_vert.traineddata", # ç¹ä¸­ç›´æ’ (1.74 MB)
        "jpn.traineddata",          # æ—¥æ–‡ (2.36 MB)
        "jpn_vert.traineddata",     # æ—¥æ–‡ç›´æ’ (2.90 MB)
        "kor.traineddata",          # éŸ“æ–‡ (1.60 MB)
    ]
    
    count1, size1 = remove_files(tessdata_dir, unnecessary_languages, "èªè¨€åŒ…")
    print(f"âœ“ ç§»é™¤ {count1} å€‹èªè¨€åŒ…ï¼Œç¯€çœ {size1:.2f} MB")
    
    # 2. ç§»é™¤è¨“ç·´å·¥å…·ï¼ˆåªéœ€è¦ tesseract.exe ä¾†åŸ·è¡Œ OCRï¼‰
    print("\n[æ­¥é©Ÿ 2/4] ç§»é™¤è¨“ç·´å·¥å…·...")
    training_tools = [
        "text2image.exe",                # è¨“ç·´ç”¨ (0.35 MB)
        "lstmtraining.exe",              # è¨“ç·´ç”¨ (0.30 MB)
        "lstmeval.exe",                  # è¨“ç·´ç”¨ (0.29 MB)
        "set_unicharset_properties.exe", # è¨“ç·´ç”¨ (0.24 MB)
        "mftraining.exe",                # è¨“ç·´ç”¨ (0.21 MB)
        "shapeclustering.exe",           # è¨“ç·´ç”¨ (0.20 MB)
        "cntraining.exe",                # è¨“ç·´ç”¨ (0.20 MB)
        "classifier_tester.exe",         # è¨“ç·´ç”¨ (0.20 MB)
        "unicharset_extractor.exe",      # è¨“ç·´ç”¨ (0.14 MB)
        "combine_lang_model.exe",        # è¨“ç·´ç”¨ (0.13 MB)
        "wordlist2dawg.exe",             # è¨“ç·´ç”¨ (0.09 MB)
        "combine_tessdata.exe",          # è¨“ç·´ç”¨ (0.06 MB)
        "dawg2wordlist.exe",             # è¨“ç·´ç”¨ (0.06 MB)
        "ambiguous_words.exe",           # è¨“ç·´ç”¨ (0.06 MB)
        "merge_unicharsets.exe",         # è¨“ç·´ç”¨ (0.05 MB)
        "tesseract-uninstall.exe",       # å®‰è£ç¨‹å¼ (0.15 MB)
        "winpath.exe",                   # å·¥å…· (0.02 MB)
    ]
    
    count2, size2 = remove_files(tesseract_dir, training_tools, "è¨“ç·´å·¥å…·")
    print(f"âœ“ ç§»é™¤ {count2} å€‹è¨“ç·´å·¥å…·ï¼Œç¯€çœ {size2:.2f} MB")
    
    # 3. ç§»é™¤ HTML æ–‡æª”
    print("\n[æ­¥é©Ÿ 3/4] ç§»é™¤æ–‡æª”æª”æ¡ˆ...")
    html_files = [
        "tesseract.1.html",
        "text2image.1.html",
        "lstmtraining.1.html",
        "lstmeval.1.html",
        "set_unicharset_properties.1.html",
        "mftraining.1.html",
        "shapeclustering.1.html",
        "cntraining.1.html",
        "classifier_tester.1.html",
        "unicharset_extractor.1.html",
        "combine_lang_model.1.html",
        "wordlist2dawg.1.html",
        "combine_tessdata.1.html",
        "dawg2wordlist.1.html",
        "ambiguous_words.1.html",
        "merge_unicharsets.1.html",
        "unicharset.5.html",
        "unicharambigs.5.html",
    ]
    
    count3, size3 = remove_files(tesseract_dir, html_files, "æ–‡æª”")
    print(f"âœ“ ç§»é™¤ {count3} å€‹æ–‡æª”æª”æ¡ˆï¼Œç¯€çœ {size3:.2f} MB")
    
    # 4. ç§»é™¤ tessdata ä¸­ä¸éœ€è¦çš„è³‡æ–™å¤¾å’Œæª”æ¡ˆ
    print("\n[æ­¥é©Ÿ 4/4] ç§»é™¤é¡å¤–çš„è³‡æ–™...")
    extra_items = []
    
    # ç§»é™¤ JAR æª”æ¡ˆï¼ˆç”¨æ–¼ ScrollView GUIï¼ŒOCR ä¸éœ€è¦ï¼‰
    jar_files = [
        "piccolo2d-core-3.0.1.jar",
        "piccolo2d-extras-3.0.1.jar",
        "ScrollView.jar",
    ]
    for jar in jar_files:
        jar_path = os.path.join(tessdata_dir, jar)
        if os.path.exists(jar_path):
            size = os.path.getsize(jar_path) / (1024 * 1024)
            try:
                os.remove(jar_path)
                extra_items.append((jar, size))
                print(f"  âœ“ ç§»é™¤: {jar} ({size:.2f} MB)")
            except Exception as e:
                print(f"  âœ— ç„¡æ³•ç§»é™¤: {jar} - {e}")
    
    # ç§»é™¤ä¸éœ€è¦çš„è³‡æ–™å¤¾
    folders_to_remove = ["configs", "tessconfigs", "script"]
    for folder in folders_to_remove:
        folder_path = os.path.join(tessdata_dir, folder)
        if os.path.exists(folder_path):
            try:
                shutil.rmtree(folder_path)
                print(f"  âœ“ ç§»é™¤è³‡æ–™å¤¾: {folder}/")
            except Exception as e:
                print(f"  âœ— ç„¡æ³•ç§»é™¤: {folder}/ - {e}")
    
    size4 = sum([item[1] for item in extra_items])
    print(f"âœ“ ç§»é™¤é¡å¤–è³‡æ–™ï¼Œç¯€çœ {size4:.2f} MB")
    
    # è¨ˆç®—æœ€çµ‚å¤§å°
    final_size = get_folder_size(tesseract_dir)
    total_saved = original_size - final_size
    percentage = (total_saved / original_size) * 100
    
    print_section("ç²¾ç°¡å®Œæˆ")
    print(f"\nğŸ“Š åŸå§‹å¤§å°: {original_size:.2f} MB")
    print(f"ğŸ“Š ç²¾ç°¡å¾Œ:   {final_size:.2f} MB")
    print(f"ğŸ’¾ ç¯€çœç©ºé–“: {total_saved:.2f} MB ({percentage:.1f}%)")
    
    print(f"\nâœ… ä¿ç•™çš„é—œéµæª”æ¡ˆ:")
    essential_files = [
        "tesseract.exe (OCR å¼•æ“)",
        "æ‰€æœ‰ DLL æª”æ¡ˆ (ç›¸ä¾å‡½å¼åº«)",
        "tessdata/eng.traineddata (è‹±æ–‡èªè¨€åŒ…)",
        "tessdata/pdf.ttf (å­—å‹æª”æ¡ˆ)",
    ]
    for f in essential_files:
        print(f"  âœ“ {f}")
    
    print(f"\nğŸ“‹ ç§»é™¤çµ±è¨ˆ:")
    print(f"  â€¢ èªè¨€åŒ…: {count1} å€‹ï¼Œ{size1:.2f} MB")
    print(f"  â€¢ è¨“ç·´å·¥å…·: {count2} å€‹ï¼Œ{size2:.2f} MB")
    print(f"  â€¢ æ–‡æª”æª”æ¡ˆ: {count3} å€‹ï¼Œ{size3:.2f} MB")
    print(f"  â€¢ é¡å¤–è³‡æ–™: {len(extra_items)} å€‹ï¼Œ{size4:.2f} MB")
    
    print("\n" + "=" * 70)
    print("ç²¾ç°¡å®Œæˆï¼OCR åŠŸèƒ½ä¸å—å½±éŸ¿ï¼Œåªä¿ç•™è‹±æ–‡è¾¨è­˜æ‰€éœ€çš„æª”æ¡ˆã€‚")
    print("=" * 70)
    
    input("\næŒ‰ Enter é€€å‡º...")

if __name__ == "__main__":
    main()
